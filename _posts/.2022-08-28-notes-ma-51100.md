---
layout: post
title: "Notes: MA 51100 - Linear Algebra and Applications"
date: 2022-09-05
excerpt: "Study notes / 2022 Fall, Purdue, ECE"
tags: [linear algrbra, matrix computation, linear equations, decomposition]
---

<style>
.highlight {
    line-height: 1;
    margin-bottom: 0;
}

li {
    text-align: left;
}

li code {
    line-height: 1;
}
</style>


> **Textbook:** [Linear Algebra and Its Applications, 4th Edition Solutions, Gilbert Strang, 2004](https://brainly.com/textbook-solutions/b-linear-algebra-applications-4th-edition-college-math-9780030105678?source=tbs-ex-book#af429062-47a4-492c-89b0-4560d692fd05){:target="_blank"}

> **Table of Contents**
> * this unordered seed list will be replaced by toc as unordered list
> {:toc}

<br/>


<!-- LECTURE 1 -->
## <i class="fa fa-file-text-o" aria-hidden="true" style="font-size:75%;margin-right:5px;"></i> Lecture 1

<ul><blockquote>
  <span style="color:#CC0000">
  <strong><i class="fa fa-tags" aria-hidden="true" style="font-size:75%;margin-right:5px;"></i> Chapters</strong>
  <br>
  1.2 - The Geometry of Linear Equations
  <br>
  1.3 - An Example of Gaussian Elimination
  <br>
  1.4 - Matrix Notation and Matrix Multiplication
  </span>
</blockquote></ul>

- <span style="color:blue">**Solving linear equations:** <u>Gaussian Elimination</u>, <u>Back-subtitution</u>, Determinants formula</span>
  - Linear equations lead to "Geometry of planes"
  - Matrix notation ```Ax=b```, Elimination/Elementary matrices = L<sub>Lower-traingular matrix</sub> x U<sub>Upper-traingular matrix</sub>
  - The number of elimination steps required to solve a system (linear equations) = Computing costs
  - <span style="color:blue">**Critical components:**</span>
    - Coefficient matrix ```A```
    - Elimination/Elementary matrix ```E```
    - Row exchanges ```P```
    - Final factors ```L``` and ```U```

- **Linear system**
  - **Rows:** Geometry of planes, Intersection of planes (singular = no solution or infinite solutions; non-singular = one solution)
  - **Columns:** Find the combination of the column vectors on the left side that produces the vector on the right side
  - <span style="color:blue">**Fact:**</span> If the n planes have no point in common, or infinitely many points, then the n columns lie in the same plane.

- **Gaussian Elimination**
  - Start by subtracting multiples of the first equation from the other equations
  - The goal is to eliminate a certain unknown from the last two equations
  - Repeat the above steps from the first equation to the last one until we **find all pivots** / reach the **"triangular" system**
  - Then we solve the system backward through **back-subtitution**
  - **Fact:** The following operations do not change the solution set
    - Interchange rows
    - Multiply rows by a non-zero number
    - Replace row by row plus multiple of another rows
    - <span style="color:blue">**The above operations are used in <u>Gaussian elimination</u> to get to <u>row echelon form</u>**</span>

- **Matrix Multiplication**
  - Two ways to multiply a matrix \\(A\\) and a vector \\(x\\) = **(1) A row at a time**, **(2) A column at a time**<br/>
    (```Ax``` is a combination of the columns of A, and the coefficients are the components of x)
  - Matrix multiplication is associative: ```(AB)C = A(BC)```
  - Matrix operations are distributive: ```A(B+C) = AB+AC``` and ```(B+C)D = BD+CD```
  - Matrix multiplication is not commutative: **Usually ```FE != EF```**

<br/>


<!-- LECTURE 2 -->
## <i class="fa fa-file-text-o" aria-hidden="true" style="font-size:75%;margin-right:5px;"></i> Lecture 2
<ul><blockquote>
  <span style="color:#CC0000">
  <strong><i class="fa fa-tags" aria-hidden="true" style="font-size:75%;margin-right:5px;"></i> Chapters</strong>
  <br>
  1.5 - Triangular Factors and Row Exchanges
  </span>
</blockquote></ul>

- **Systems**
  - The model system ```Ax = b```, after several elimination steps, becomes an **equivalent system ```Ux = c```**
  - Then the equivalent system can be solved by **back-subtitution**

- **Matrices**
  - The **```U```** in the equivalent system is **upper triangular** (all entries below the diagonal are zero)
  - The matrices applied in the elimination steps are called **elementary matrices** (e.g., G, E, A in ```GFEA = U```)
  - We could multiply GFE together to find the single matrix that takes A to U, and it is **lower triangular**

- <span style="color:blue">**Triangular factorization**</span>
  - By undoing elimination steps from the equivalent system, we derive **triangular factorization of A, which is ```A = LU```**<br/>
  - Since ```GFEA = U``` we can get **<code>L = E<sup>-1</sup> F<sup>-1</sup> G<sup>-1</sup></code>** then **<span style="color:blue"><code>A = LU = E<sup>-1</sup> F<sup>-1</sup> G<sup>-1</sup> U</code></span>**
  - Triangular factorization ```A = LU``` **with no exchanges of rows**<br/>
    - **<span style="color:blue"><code>L = E<sup>-1</sup> F<sup>-1</sup> G<sup>-1</sup></code> is lower triangular</span>**
    - **<span style="color:blue">```U``` is upper triangular and the row echelon form</span>** (derived by Gaussian elimination)
    - **The diagonal entries of U are the pivots**
  - Triangular factorization ```PA = LU``` **with exchanges of rows**<br/>
    - The matrix PA will not need row exchanges
    - In other words, With the rows reordered in advance, **PA allows the standard factorization into L times U**
    - In the singular case, no P can produce a full set of pivots: elimination fails

- **One Linear System = Two Triangular Systems**
  - In fact, L and U are the right matrices to solve ```Ax = b```, and A could be thrown away
  - **Splitting of Ax = b:** ```Lc = b``` and then ```Ux = c```
  - **<span style="color:blue">Factor:</span>** from A find its factors L and U
  - **<span style="color:blue">Solve:</span>** from L and U and b find the solution x
  - **<span style="color:blue">Factor out D:</span>** the triangular factorization can be written **```A = LDU```**<br/>
    where L and U have 1s on the diagonal and **D is the diaonal matrix of pivots**
  - **<span style="color:blue">The LDU factorization and LU factorization are uniquely determined by A</span>**

<br/>


<!-- LECTURE 3 -->
## <i class="fa fa-file-text-o" aria-hidden="true" style="font-size:75%;margin-right:5px;"></i> Lecture 3

<ul><blockquote>
  <span style="color:#CC0000">
  <strong><i class="fa fa-tags" aria-hidden="true" style="font-size:75%;margin-right:5px;"></i> Chapters</strong>
  <br>
  1.6 - Inverses and Transposes
  <br>
  Chapter 1 Review
  </span>
</blockquote></ul>

- **Inverse**
  - Definition: **<span style="color:blue">Matrix A is invertible if it has a left inverse and a right inverse</span>**, written as <code>Ax = b, x = A<sup>-1</sup>b</code>
    - Left  inverse: <code>B<sub>nxm</sub> A<sub>mxn</sub> = <strong>1<sub>n</sub></strong></code>
    - Right inverse: <code>A<sub>mxn</sub> B<sub>nxm</sub> = <strong>1<sub>m</sub></strong></code>
  - Remark:
    - A has to be ```nxn```
    - **An inverse is impossible when ```Ax = 0``` and ```x != 0```**
    - If A is invertible, the one and only solution to ```Ax = b``` is <code>x = A<sup>-1</sup>b</code>
    - **<span style="color:blue">The inverse exists if and only if elimination produces n pivots (row exchanges allowed)</span>**
    - Left inverse = Right inverse
    - If A is square and has left inverse, A is invertible
  - **<span style="color:blue">Compute: Full Gauss (Gauss-Jordan method)</span>**
    - ```[A | I]``` &rarr; through a series of elementary matrices <code>E<sub>n</sub> ... E<sub>1</sub></code> &rarr; <code>[I | A<sup>-1</sup>]</code>
    - **Get n pivots and <code>A<sup>-1</sup> = E<sub>n</sub> ... E<sub>1</sub></code>**
  - Property:
    - <code>(AB)<sup>-1</sup> = B<sup>-1</sup>A<sup>-1</sup></code>
    - <code>(ABC)<sup>-1</sup> = C<sup>-1</sup>B<sup>-1</sup>A<sup>-1</sup></code>
    - <code>(B<sup>-1</sup>A<sup>-1</sup>)AB = B<sup>-1</sup>(A<sup>-1</sup>A)B = 1<sub>n</sub></code>
    - <code>AB(B<sup>-1</sup>A<sup>-1</sup>) = A(BB<sup>-1</sup>)A<sup>-1</sup> = 1<sub>n</sub></code>

- **Transpose**
  - Definition: **<span style="color:blue">The i-th row of A becomes the i-th column of A<sup>T</sup></span>**, written as <code>(A)<sub>ij</sub> = A<sub>ij</sub>, (A<sup>T</sup>)<sub>ij</sub> = A<sub>ji</sub></code>
  - Property:
    - <code>A<sub>nxm</sub>, A<sup>T</sup><sub>mxn</sub></code>
    - <code>(AB)<sup>T</sup> = B<sup>T</sup>A<sup>T</sup></code>
    - <code>(A + B)<sup>T</sup> = A<sup>T</sup> + B<sup>T</sup></code>
    - <code>(A<sup>-1</sup>)<sup>T</sup> = (A<sup>T</sup>)<sup>-1</sup></code>
    - **(column vector)<sup>T</sup> = row vector**<br/>
      **<code><u, v> = u<sup>T</sup>v</code>**, **<code><Au, v> = (Au)<sup>T</sup>v = u<sup>T</sup>A<sup>T</sup>v = <u, A<sup>T</sup>v></code>**

- **Symmetric**
  - Definition: **<span style="color:blue">A symmetric matrix is a matrix that equals its own transpose</span>**, written as <code>A<sup>T</sup> = A</code>
  - Property:
    - The matrix is necessarily square
    - A symmetric matrix need not be invertible, but if its inverse <code>A<sup>-1</sup></code> exists, it is also symmetric
    - **<span style="color:blue">Symmetric</span> <code>A<sup>T</sup> = A</code>**
    - **<span style="color:blue">Skew-symmetric</span> <code>A<sup>T</sup> = -A</code>**
    - **A = \\( \frac{1}{2} \\) [(A + A<sup>T</sup>) + (A - A<sup>T</sup>)]**

- **Exercise:** For <code>P = P<sub>12</sub> P<sub>23</sub></code> check the followings: <code>P<sup>T</sup></code>, <code>P<sup>T</sup> = P<sup>-1</sup></code>, <code>P<sup>2</sup> = P<sup>-1</sup></code>, <code>P<sup>3</sup> = I</code>

<br/>


<!-- LECTURE 4 -->
## <i class="fa fa-file-text-o" aria-hidden="true" style="font-size:75%;margin-right:5px;"></i> Lecture 4

<ul><blockquote>
  <span style="color:#CC0000">
  <strong><i class="fa fa-tags" aria-hidden="true" style="font-size:75%;margin-right:5px;"></i> Chapters</strong>
  <br>
  2.1 - Vector Spaces and Subspaces
  </span>
</blockquote></ul>

- **Vector Spaces**
  - Vectors are things you can **add and scale (multiply)**
  - **<span style="color:blue">Within all vector spaces, two operations are possible: ADD and MULTIPLY (i.e., linear combinations)</span>**
  - The space \\( \mathbf{\mathbb{R}} \\)**<sup>n</sup>** consists of all column vectors with n components
    - \\( \mathbf{\mathbb{R}} \\)**<sup>1</sup>** is a line
    - \\( \mathbf{\mathbb{R}} \\)**<sup>2</sup>** is represented by the usual x-y plane (the two components of the vector become the x and y coordinates)
    - \\( \mathbf{\mathbb{R}} \\)**<sup>3</sup>** is a 3D space (the three components of a vector give a point)
  - Property:
    - Associative ```(X+Y)+Z = X+(Y+Z)```
    - Commutative ```X+Y = Y+X```
    - Zero vector ```X+0 = X```
    - For all ```X``` there is a ```-X``` such that ```X+(-X) = 0```
    - ```c(X+Y) = cX+cY```
    - ```c(dX) = (cd)X```
    - <code>(c<sub>1</sub>+c<sub>2</sub>)X = c<sub>1</sub>x+c<sub>2</sub>X</code>
    - ```1X = X```
- **Subspaces**
  - A subspace of a vector space is a nonempty subset
  - A subspace is a subset that is **<span style="color:blue">closed under addition and scalar multiplication</span>**
  - A subspace must satisfy the requirements for a vector space: **<span style="color:blue">Linear combinations stay in the subspace</span>**
  - **<span style="color:blue">The zero vector will belong to every subspace</span>**
- **Column space ```C(A)```**
  - For <code>A<sub>nxm</sub></code> the column space of ```A``` is from \\( \mathbb{R} \\)<sup>m</sup> to \\( \mathbb{R} \\)<sup>n</sup>
  - For <code>A<sub>nxm</sub></code> the column space of ```A``` is a **subspace of \\( \mathbf{\mathbb{R}} \\)<sup>n</sup>**
  - **<span style="color:blue">The column space contains all linear combinations of the columns of A</span>**
- **Null space ```N(A)```**
  - For <code>A<sub>nxm</sub></code> , the null space of ```A``` is a **subspace of \\( \mathbf{\mathbb{R}} \\)<sup>m</sup>**
  - **<span style="color:blue">The nullspace of A consists of all vectors ```x``` such that ```Ax = 0```</span>**
  - The **solutions to ```Ax = 0```** form a vector space called the nullspace of A

<br/>


<!-- LECTURE 5 -->
## <i class="fa fa-file-text-o" aria-hidden="true" style="font-size:75%;margin-right:5px;"></i> Lecture 5

<ul><blockquote>
  <span style="color:#CC0000">
  <strong><i class="fa fa-tags" aria-hidden="true" style="font-size:75%;margin-right:5px;"></i> Chapters</strong>
  <br>
  2.2 - Solving Ax = 0 and Ax = b
  </span>
</blockquote></ul>

- From rectangular matrix ```U```, which may not have a full set of pivots, to a row reduced form ```R```
- **Row reduced form** is the simplest matrix that elimination can give, and ```R``` reveals all solutions of ```Ax = b```
- **Invertible matrix ```A```**
  - The nullspace contains only ```x = 0```
  - The column space is the whole space since there is always a solution for every ```b```
- **New questions: the nullspace contains more than the zero vector, the column space contains less than all vectors**
  - Any vector <code>x<sub>n</sub></code> in the nullspace can be added to a particular solution <code>x<sub>p</sub></code>
  - **<span style="color:blue">The solutions to all linear equations have this form <code>x = x<sub>p</sub> + x<sub>n</sub></code> as <code>Ax<sub>p</sub> = b,  Ax<sub>n</sub> = 0</code></span>**
  - **The difference between any two solutions is a homogeneous solution**
  - Homogeneous solutions form a vector space that we can add and scale them but still be a solution
  - When the column space doesn't contain every ```b```, **<span style="color:blue">we need the conditions on ```b``` that make ```Ax = b``` solvable</span>**

  > For any **matrix <code>A<sub>mxn</sub></code>** there is a permutation ```P```, a lower triangular```L``` with unit diagonal, and an **echelon matrix <code>U<sub>mxn</sub></code>,** such that ```PA = LU```

- **<span style="color:blue">Echelon form</span> <sup>staircase pattern</sup> is upper traingular** but its pivots are not on the main diagonal
  1. The pivots are the first nonzero entries in their rows
  2. Below each pivot is a column of zeros, obtained by elimination
  3. Each pivot lies to the right of the pivot in the row above, **this produces the staircase pattern, and zero rows come last**
- **<span style="color:blue">Reduced row echelon form</span>**
  - The matrix R is the final result of elimination on A (still upper traingular), and **all pivors are 1**
  - **The pivot rows and columns form an identity submatrix**
  - Thus the reduced row echelon form of a square invertible (non-signular) matrix is the identity matrix
  - **```Rx = 0``` has the same solutions as ```Ux = 0``` and ```Ax = 0```**
  - When the equation is ```Ax = 0``` the particular solution **<code>x<sub>p</sub></code> was the zero vector**
  - For **```Ax = b, Ux = c, Rx = d```**, in reduced row echelon ```R``` form, **the entries of ```d``` go directly into <code>x<sub>p</sub></code>**
- **<span style="color:blue">Pivot variabels / Free variables</span>**
  - **Pivot variables:** those that correspond to columns with pivots **<span style="color:blue"><code>R<sub>rank</sub> = #<sub>pivot variables</sub></code></span>**
  - **Free variables:** those that correspond to columns without pivots
  - To find the most general solution to **```Rx = 0```** we may **assign arbitrary values to the free variables**
  - **The combinations of special solutions form the nullspace are all solutions to ```Ax = 0```**
  - The nullspace has the same dimension as the number of free variables and special solutions
  - <span style="color:blue">We count the **free variables for the nullspace,** and we count the **pivot variables for the column space**</span>

  > **Elimination** reveals the pivot variables and free variables. If there are ```r``` pivots, there are r pivot variables and ```n - r``` free variables. That important number ```r``` will be given a name - it is the **rank of the matrix.**
    Then the last ```m - r``` rows of U and R are zero, so **there is a solution only if the last ```m - r``` entries of c and d are also zero.**

  <div class="language-text highlighter-rouge"><pre class="highlight"><code>
    1x<sub>1</sub> + 2x<sub>2</sub> + 3x<sub>3</sub> +  5x<sub>4</sub> = b<sub>1</sub>
    2x<sub>1</sub> + 4x<sub>2</sub> + 8x<sub>3</sub> + 12x<sub>4</sub> = b<sub>2</sub>
    3x<sub>1</sub> + 6x<sub>2</sub> + 7x<sub>3</sub> + 13x<sub>4</sub> = b<sub>2</sub>


    Ax = b
        1 2 3  5 | b<sub>1</sub>
        2 4 8 12 | b<sub>2</sub>
        3 6 7 13 | b<sub>3</sub>

    Ux = c
        1 2 3 5 | b<sub>1</sub>
        0 0 2 2 | b<sub>2</sub> - 2b<sub>1</sub>
        0 0 0 0 | b<sub>3</sub> + b<sub>2</sub> - 5b<sub>1</sub>

    Rx = d
        1 2 0 2 | 4b<sub>1</sub> - 3b<sub>2</sub> / 2
        0 0 1 1 | (b<sub>2</sub> - 2b<sub>1</sub>) / 2
        0 0 0 0 | b<sub>3</sub> + b<sub>2</sub> - 5b<sub>1</sub>


    Pivot variables: x<sub>1</sub>, x<sub>3</sub>
    Free  variables: x<sub>2</sub>, x<sub>4</sub>

    ====================================================================================

    To get homogeneous solution: 
        (1) Back-substitution in Ux = 0
        (2) Just switch signs in Rx = 0

        --> 1 "2" 0 "2"    --> N = -2   -2
            0 "0" 1 "1"             1 , -1
            0 "0" 0 "0"             0    0
                                    0    1

    To get particular solution:
        - b<sub>3</sub> + b<sub>2</sub> - 5b<sub>1</sub> = 0, this makes Ax = b solvable and b is in the column space
        - the entries of d go directly into x<sub>p</sub>

        --> let b = (0, 6, -6)
            4b<sub>1</sub> - 3b<sub>2</sub> / 2 = -9 = x<sub>1</sub>
            (b<sub>2</sub> - 2b<sub>1</sub>) / 2 = 3 = x<sub>3</sub>
            0 = x<sub>2</sub> = x<sub>4</sub>

  </code></pre></div>

<br/>


<!-- LECTURE 6 -->
## <i class="fa fa-file-text-o" aria-hidden="true" style="font-size:75%;margin-right:5px;"></i> Lecture 6

<ul><blockquote>
  <span style="color:#CC0000">
  <strong><i class="fa fa-tags" aria-hidden="true" style="font-size:75%;margin-right:5px;"></i> Chapters</strong>
  <br>
  2.3 - Linear Independence, Basis, and Dimension
  </span>
</blockquote></ul>

<ul><blockquote>
  The <strong>rank</strong> was introduced as <strong>the number of pivots in the elimination process.</strong> Equivalently, the final matrix U has r nonzero rows.
  The rank counts the number of genuinely <strong>independent rows</strong> in the matrix A. 
</blockquote></ul>

- **Linear independence or dependence**
  - **<code>c<sub>1</sub>v<sub>1</sub> + c<sub>2</sub>v<sub>2</sub> + ... + c<sub>k</sub>v<sub>k</sub></code>**
  - Trivial combination, with all weights <code>c<sub>i</sub> = 0</code>, obviously produces the zero vector
  - **Whether this is the only way to produce zero**
    - If so, the vectors are independent
    - If any other combination of the vectors gives zero, they are dependent
    
    > Suppose c<sub>1</sub> v<sub>1</sub> + ... + c<sub>k</sub>v<sub>k</sub> = 0 only happens when c<sub>i</sub> = ... = c<sub>k</sub> = 0. Then the vectors v<sub>i</sub>, ... , v<sub>k</sub> are **linearly independent.** If any c's are nonzero. the v's are **linearly dependent.** One vector is a combination of the others.<br/>

    > Linear dependence is easy to visualize in three-dimensional space, when all vectors go out from the origin. Two vectors are dependent if they lie on the same line. **Three vectors are dependent if they lie in the same plane.**<br/>
  
  - **<span style="color:blue">The columns of <code>A<sub>mxn</sub></code> are independent exactly when ```N(A) = {zero vector}```</span>**
  - **<span style="color:blue">A set of n vectors in R<sup>m</sup> must be linearly dependent if ```n > m```</span>**
  <br/><br/>

- **Spanning a subspace** 
  - If a vector space ```V``` consists of all linear combinations of <code>w<sub>1</sub>, ..., w<sub>L</sub></code>, then these vectors span the space
  - Every vector ```v``` in ```V``` is some combination of the ```w```'s: <code>v = c<sub>1</sub>w<sub>1</sub>, ..., c<sub>L</sub>w<sub>L</sub></code> for some coefficients <code>c<sub>i</sub></code>
  - **The column space of ```A``` is spanned by the columns,** in other words, **their combinations produce the whole space**
  - The coordinate vectors <code>e<sub>1</sub>, ..., e<sub>n</sub>,</code> coming from the identity matrix span **<code>R<sup>n</sup></code>**  
  <br/>

- **Basis for a subspace** (a set of vectors)
  - To decide if ```b``` is a combination of the columns, we try to solve ```Ax = b```
  - To decide if the columns are independent, we solve ```Ax = 0```
  - **<span style="color:blue">Spanning involves the column space, and independence involves the nullspace</span>**
  - A **<span style="color:blue">basis</span> for ```V```** is a sequence of vectors having two properties at once:
    1. **The vectors are linearly independent** (not too many vectors)
    2. They **span the space ```V```** (not too few vectors)
  - **<span style="color:blue">Every vector in the space is a combination of the basis vectors</span>** because the basis vectors span
  - Due to the linear independence there is **only one way to write any vector ```v``` as a combination of the basis vectors**
  <br/><br/>

- **Dimension of a subspace** (a number)
  - <span style="color:blue">The **dimension** of a vector space is the **minimum number of vectors spanning** (these are linearly independent)</span>
  - A space has infinitely many different bases, but the number of basis vectors is a property of the space itself
  - This number shared by all bases and expresses the number of **degrees of freedom** of the space, **is the dimension of ```V```**
  - **<span style="color:blue">A basis is a MAX independent set (cannot be made larger) and also a MIN spanning set (cannot be made smaller)</span>**
    - Any linearly independent set in ```V``` can be extended to a basis, by adding more vectors if necessary
    - Any spanning set in ```V``` can be reduced to a basis, by discarding vectors if necessary.

    > **<u>Proof using contradiction:</u>**<br/>
      (1) **If <code>v<sub>1</sub>, ..., v<sub>m</sub></code> and <code>w<sub>1</sub>, ..., w<sub>n</sub></code> are both bases** for the same vector space, **then suppose ```n > m```**<br/>
      (2) Since ```v```'s form a basis, they must span the space. Every <code>w<sub>i</sub></code> can be written as a combination of the ```v```'s <br/>
      (3) **W<sub>1xn</sub> = V<sub>1xm</sub> A<sub>mxn</sub>** = <code>W = (w<sub>1</sub> w<sub>2</sub> ... w<sub>n</sub>) = (v<sub>1</sub> ... v<sub>m</sub>) (a<sub>11</sub> ... a<sub>m1</sub>)<sup>T</sup></code><br/>
      (4) The key is that **```A``` is a short, wide matrix due to ```n > m```, thus there is a nonzero solution to ```Ax = 0```**<br/>
      (5) Then ```VAx = 0, Wx = 0```, **```W``` cannot be a basis since a combination of ```w```'s gives zero, not linearly independent**

    > In a subspace of dimension k, no set of more than k vectors can be independent, and no set of fewer than k vectors can span the space.

<br/>


<!-- LECTURE 6 -->
## <i class="fa fa-file-text-o" aria-hidden="true" style="font-size:75%;margin-right:5px;"></i> Lecture 7 - 8

<ul><blockquote>
  <span style="color:#CC0000">
  <strong><i class="fa fa-tags" aria-hidden="true" style="font-size:75%;margin-right:5px;"></i> Chapters</strong>
  <br>
  2.4 - The Four Fundamental Subspaces<br/>
  2.5 - Graphs and Networks<br/>
  2.6 - Linear Transformations<br/>
  </span>
</blockquote></ul>

- 

<br/>


<!-- ASSIGNMENT 1 -->
## <i class="fa fa-file-code-o" aria-hidden="true" style="font-size:75%;margin-right:5px;"></i> Assignment 1

- **1.2 -- The Geometry of Linear Equations**<br/>
  [```Q3```](https://brainly.com/textbook-solutions/q-3-recommended-intersection-planes-u-v-w){:target="_blank"}
- **1.3 -- An Example of Gaussian Elimination**<br/>
  [```Q11```](https://brainly.com/textbook-solutions/q-problems-10-19-study-elimination-3-3-systems-5){:target="_blank"},
  [```Q12```](https://brainly.com/textbook-solutions/q-problems-10-19-study-elimination-3-3-systems-6){:target="_blank"}
- **1.4 -- Matrix Notation and Matrix Multiplication**<br/>
  [```Q2```](https://brainly.com/textbook-solutions/q-2-working-column-time-compute-products-array){:target="_blank"},
  [```Q3```](https://brainly.com/textbook-solutions/q-3-inner-products-matrix-product-array-lll){:target="_blank"},
  [```Q13```](https://brainly.com/textbook-solutions/q-13-trial-error-examples-2-2-matrices-4){:target="_blank"},
  [```Q17```](https://brainly.com/textbook-solutions/q-17-following-matrices-guaranteed-equal-b-2){:target="_blank"},
  [```Q29```](https://brainly.com/textbook-solutions/q-problems-22-31-elimination-matrices-29-3-3-1){:target="_blank"}
- **1.5 -- Triangular Factors and Row Exchanges**<br/>
  [```Q4```](https://brainly.com/textbook-solutions/q-4-apply-elimination-produce-factors-l-u){:target="_blank"},
  [```Q15```](https://brainly.com/textbook-solutions/q-15-p-l-d-u-factorizations-check){:target="_blank"}

<br/>


<!-- ASSIGNMENT 2 -->
## <i class="fa fa-file-code-o" aria-hidden="true" style="font-size:75%;margin-right:5px;"></i> Assignment 2

- **1.6 -- Inverses and Transposes**<br/>
  [```Q4```](https://brainly.com/textbook-solutions/q-4-invertible-b-c-prove-quickly-b-1){:target="_blank"},
  [```Q6```](https://brainly.com/textbook-solutions/q-6-use-gauss-jordan-method-invert-a-1){:target="_blank"},
  [```Q13```](https://brainly.com/textbook-solutions/q-13-array-l-3-1-array-b){:target="_blank"},
  [```Q14```](https://brainly.com/textbook-solutions/q-14-b-square-b-b-t-symmetric){:target="_blank"}
- **Chapter 1 Review**<br/>
  [```Q12```](https://brainly.com/textbook-solutions/q-1-12-true-false-reason-true-counterexample-4){:target="_blank"},
  [```Q19```](https://brainly.com/textbook-solutions/q-1-19-solve-elimination-solution-aligned-u){:target="_blank"}
- **2.1 -- Vector Spaces and Subspaces**<br/>
  [```Q2```](https://brainly.com/textbook-solutions/q-2-following-subsets-r-3-actually-subspaces-2){:target="_blank"},
  [```Q3```](https://brainly.com/textbook-solutions/q-3-column-space-nullspace-matrices-array-cc){:target="_blank"},
  [```Q5```](https://brainly.com/textbook-solutions/q-5-addition-scalar-multiplication-required-satisfy-rules-3){:target="_blank"},
  [```Q25```](https://brainly.com/textbook-solutions/q-problems-21-30-column-spaces-c-equation-x-9){:target="_blank"}

<br/>


<!-- ASSIGNMENT 3 -->
## <i class="fa fa-file-code-o" aria-hidden="true" style="font-size:75%;margin-right:5px;"></i> Assignment 3

- **2.2 -- Solving Ax = 0 and Ax = b**<br/>
  [```Q2```](https://brainly.com/textbook-solutions/q-2-reduce-b-echelon-form-ranks-variables){:target="_blank"},
  [```Q5```](https://brainly.com/textbook-solutions/q-5-write-complete-solutions-x-x-p){:target="_blank"},
  [```Q6```](https://brainly.com/textbook-solutions/q-6-set-attainable-right-hand-sides-b-column){:target="_blank"},
  [```Q20```](https://brainly.com/textbook-solutions/q-20-rank-r-r-r-submatrix-s){:target="_blank"},
  [```Q22```](https://brainly.com/textbook-solutions/q-22-ranks-b-m-rank-1-matrix){:target="_blank"}
- **2.3 -- Linear Independence, Basis, and Dimension**<br/>
  [```Q1```](https://brainly.com/textbook-solutions/q-problems-1-10-linear-independence-linear-dependence-1){:target="_blank"},
  [```Q7```](https://brainly.com/textbook-solutions/q-problems-1-10-linear-independence-linear-dependence-7){:target="_blank"},
  [```Q18```](https://brainly.com/textbook-solutions/q-18-decide-b-sub-space-spanned-w-2){:target="_blank"},
  [```Q32```](https://brainly.com/textbook-solutions/q-problems-19-37-requirements-basis-32-dimensions-vector-3){:target="_blank"},
  [```Q37```](https://brainly.com/textbook-solutions/q-problems-19-37-requirements-basis-37-basis-subspaces-3){:target="_blank"}

<br/>


<!-- ASSIGNMENT 4 -->
## <i class="fa fa-file-code-o" aria-hidden="true" style="font-size:75%;margin-right:5px;"></i> Assignment 4

- **2.4 -- The Four Fundamental Subspaces**<br/>
  [```Q3```](https://brainly.com/textbook-solutions/q-3-dimension-basis-fundamental-subspaces-array-llll){:target="_blank"},
  [```Q7```](https://brainly.com/textbook-solutions/q-7-matrix-row-space-nullspace-contain-1){:target="_blank"},
  [```Q8```](https://brainly.com/textbook-solutions/q-8-suppose-solution-x-0-m-equations){:target="_blank"}
- **2.5 -- Graphs and Networks**<br/>
  [```Q1```](https://brainly.com/textbook-solutions/q-1-3-node-triangular-graph-figure-following){:target="_blank"},
  [```Q2```](https://brainly.com/textbook-solutions/q-2-3-3-matrix-directly-columns-vector){:target="_blank"},
  [```Q3```](https://brainly.com/textbook-solutions/q-3-directly-rows-vector-f-row-space){:target="_blank"}
- **2.6 -- Linear Transformations**<br/>
  [```Q1```](https://brainly.com/textbook-solutions/q-1-matrix-effect-rotating-vector-90-projecting){:target="_blank"},
  [```Q7```](https://brainly.com/textbook-solutions/q-7-space-p-3-cubic-polynomials-matrix){:target="_blank"},
  [```Q8```](https://brainly.com/textbook-solutions/q-8-cubics-p-3-fourth-degree-polynomials-p){:target="_blank"},
  [```Q18```](https://brainly.com/textbook-solutions/q-18-vector-space-p-3-p-x){:target="_blank"}

<br/>


<!-- ASSIGNMENT 5 -->
## <i class="fa fa-file-code-o" aria-hidden="true" style="font-size:75%;margin-right:5px;"></i> Assignment 5

- **Chapter 2 Review**<br/>
  [```Q4```](https://brainly.com/textbook-solutions/q-1-4-echelon-form-u-array-ccccc){:target="_blank"},
  [```Q5```](https://brainly.com/textbook-solutions/q-1-5-rank-nullspace-array-lll-0){:target="_blank"}
- **3.1 -- Orthogonal Vectors and Subspaces**<br/>
  [```Q1```](https://brainly.com/textbook-solutions/q-1-lengths-inner-product-x-1-4){:target="_blank"},
  [```Q2```](https://brainly.com/textbook-solutions/q-2-example-r-2-linearly-independent-vectors){:target="_blank"},
  [```Q5```](https://brainly.com/textbook-solutions/q-5-pairs-orthogonal-vectors-v-1-v){:target="_blank"},
  [```Q12```](https://brainly.com/textbook-solutions/q-12-basis-orthogonal-complement-row-space-array){:target="_blank"}
- **3.2 -- Cosines and Projections onto Lines**<br/>
  [```Q3```](https://brainly.com/textbook-solutions/q-3-multiple-1-1-1-closest-point){:target="_blank"},
  [```Q5```](https://brainly.com/textbook-solutions/q-5-n-dimensions-angle-does-vector-1){:target="_blank"},
  [```Q8```](https://brainly.com/textbook-solutions/q-8-methane-molecule-ch-4-arranged-carbon){:target="_blank"},
  [```Q12```](https://brainly.com/textbook-solutions/q-12-matrix-projects-point-plane-line-x){:target="_blank"}

<br/>


<!-- ASSIGNMENT 6 -->
## <i class="fa fa-file-code-o" aria-hidden="true" style="font-size:75%;margin-right:5px;"></i> Assignment 6

- **3.3 --  Projections and Least Squares**<br/>
  [```Q3```](https://brainly.com/textbook-solutions/q-3-solve-x-b-squares-p-x){:target="_blank"},
  [```Q4```](https://brainly.com/textbook-solutions/q-4-write-e-2-x-b-2-set){:target="_blank"},
  [```Q12```](https://brainly.com/textbook-solutions/q-12-v-subspace-spanned-1-1-0-3){:target="_blank"},
  [```Q24```](https://brainly.com/textbook-solutions/q-24-best-straight-line-fit-following-measurements-sketch){:target="_blank"}
- **3.4 -- Orthogonal Bases and Gram-Schmidt**<br/>
  [```Q6```](https://brainly.com/textbook-solutions/q-6-column-matrix-q-array-cc-1){:target="_blank"},
  [```Q9```](https://brainly.com/textbook-solutions/q-9-vectors-q-1-q-2-q){:target="_blank"},
  [```Q13```](https://brainly.com/textbook-solutions/q-13-apply-gram-schmidt-process-array-l-0){:target="_blank"},
  [```Q21```](https://brainly.com/textbook-solutions/q-21-closest-function-x-b-x-function){:target="_blank"},
  [```Q22```](https://brainly.com/textbook-solutions/q-22-setting-derivative-zero-value-b-1){:target="_blank"},
  [```Q24```](https://brainly.com/textbook-solutions/q-24-fourth-legendre-polynomial-cubic-x-3){:target="_blank"}

<br/>


<!-- ASSIGNMENT 7 -->
## <i class="fa fa-file-code-o" aria-hidden="true" style="font-size:75%;margin-right:5px;"></i> Assignment 7

- **3.5 --  The Fast Fourier Transform**<br/>
  [```Q1```](https://brainly.com/textbook-solutions/q-1-f-2-f-4-4-4){:target="_blank"},
  [```Q5```](https://brainly.com/textbook-solutions/q-5-solutions-equation-e-i-x-1){:target="_blank"},
  [```Q8```](https://brainly.com/textbook-solutions/q-8-solve-y-2-0-2-0){:target="_blank"},
  [```Q9```](https://brainly.com/textbook-solutions/q-9-y-1-1-1-1-c-1){:target="_blank"},
  [```Q11```](https://brainly.com/textbook-solutions/q-11-compute-y-f-4-c-steps){:target="_blank"}
- **Appendix A -- Intersection, Sum, and Product of Spaces**<br/>
  [```Q1```](https://brainly.com/textbook-solutions/q-1-suppose-s-t-subspace-r-13-1){:target="_blank"},
  [```Q2```](https://brainly.com/textbook-solutions/q-2-intersections-following-pairs-subspace-x-y-plane-1){:target="_blank"},
  [```Q4```](https://brainly.com/textbook-solutions/q-4-v-w-contains-zero-vector-equation){:target="_blank"},
  [```Q6```](https://brainly.com/textbook-solutions/q-6-v-w-0-v-w-called){:target="_blank"},
  [```Q8```](https://brainly.com/textbook-solutions/q-8-prove-equation-3-rank-b-rank){:target="_blank"}
- <span style="color:blue">**Midterm -- Chapter 1 - 3**</span>

<br/>

> **Author:** Yuan-Yao Lou / Ph.D. student, ECE, Purdue<br/>
  <small>(Last update: Sep 05, 2022)</small><br/>